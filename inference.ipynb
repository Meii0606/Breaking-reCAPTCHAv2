{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meii0606/Breaking-reCAPTCHAv2/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10-414/714: Deep Learning Systems - Final Project\n",
        "\n",
        "\n",
        "## **Sparse Matrix Multiplication on Graph Neural Network**\n",
        "\n",
        "**By Andrew Zhang, Jinkai Qiu & Yimei Wu**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In this project, we are going to implement **sparse matrix** class supported in Needle, **forward and backward pass of sparse matrix multiplication**, and its **application on Graph Neural Network(GNN)**.\n",
        "\n",
        "In this notebook, we are going to show how to **define sparse matrix**, perform **sparse matrix multiplication** and compare it with normal dense matrix multiplication. In addition, we will also show how it can be used in **GNN training.**\n",
        "\n"
      ],
      "metadata": {
        "id": "87NGEASXY4Ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone Required Repo and Install Required Packages"
      ],
      "metadata": {
        "id": "vtBJoltybBDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW1iuoBMCYyp",
        "outputId": "502a1865-ca44-4d51-9b4a-a8c4937ea77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/10714\n",
            "/content/drive/MyDrive/10714/final_proj\n",
            "Cloning into 'gnn_with_spmm'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 248 (delta 102), reused 193 (delta 57), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (248/248), 707.46 KiB | 6.37 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm\n",
            "Already up to date.\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (2.13.6)\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/10714\n",
        "!mkdir -p final_proj\n",
        "%cd /content/drive/MyDrive/10714/final_proj\n",
        "!git clone https://github.com/AndrewZhang76/gnn_with_spmm.git\n",
        "%cd gnn_with_spmm/\n",
        "!git pull\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build"
      ],
      "metadata": {
        "id": "PidjQAHYbNf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/\n",
        "!make"
      ],
      "metadata": {
        "id": "-U1A2kF6CpzT",
        "outputId": "78b00de3-a808-4fc1-de73-3059eab593a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm\n",
            "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:57 (find_package):\n",
            "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
            "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
            "  set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- CUDA_FOUND: TRUE\n",
            "-- Found cuda, building cuda backend\n",
            "Wed Dec 11 17:55:11 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (1.0s)\n",
            "-- Generating done (0.7s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ],
      "metadata": {
        "id": "i4J1P8RQi38J",
        "outputId": "19babfd5-2020-4ee6-8159-e85b2164d46f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class CoraDataset:\n",
        "    \"\"\"\n",
        "    A simple class for the Cora dataset.\n",
        "    Processes the data from .content and .cites files.\n",
        "    Returns:\n",
        "        - X: Feature matrix (np.array of shape [num_nodes, num_features])\n",
        "        - y: Labels (np.array of shape [num_nodes])\n",
        "        - adjacency_matrix: Dense adjacency matrix (np.array of shape [num_nodes, num_nodes])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, content_file: str, cites_file: str):\n",
        "        \"\"\"\n",
        "        Initializes the dataset with provided file paths.\n",
        "\n",
        "        Args:\n",
        "            content_file (str): Path to the .content file.\n",
        "            cites_file (str): Path to the .cites file.\n",
        "        \"\"\"\n",
        "        self.content_file = content_file\n",
        "        self.cites_file = cites_file\n",
        "\n",
        "        # These will store the processed data\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.adjacency_matrix = None\n",
        "        self.label_mapping = None\n",
        "\n",
        "        # Load and process the data\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Loads and processes node features, labels, and edges.\"\"\"\n",
        "        nodes = []\n",
        "        labels = []\n",
        "        features = []\n",
        "\n",
        "        # Read the .content file\n",
        "        with open(self.content_file, 'r') as f:\n",
        "            for line in f:\n",
        "                elements = line.strip().split('\\t')\n",
        "                nodes.append(elements[0])\n",
        "                features.append([float(x) for x in elements[1:-1]])\n",
        "                labels.append(elements[-1])\n",
        "\n",
        "        # Encode labels into integers\n",
        "        self.label_mapping = {label: idx for idx, label in enumerate(sorted(set(labels)))}\n",
        "        encoded_labels = [self.label_mapping[label] for label in labels]\n",
        "\n",
        "        # Convert features and labels to NumPy arrays\n",
        "        self.X = np.array(features, dtype=np.float32)\n",
        "        self.y = np.array(encoded_labels, dtype=np.int64)\n",
        "\n",
        "        # Build the adjacency matrix\n",
        "        num_nodes = len(nodes)\n",
        "        node_index = {node: idx for idx, node in enumerate(nodes)}\n",
        "        self.adjacency_matrix = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
        "\n",
        "        with open(self.cites_file, 'r') as f:\n",
        "            for line in f:\n",
        "                src, dst = line.strip().split('\\t')\n",
        "                if src in node_index and dst in node_index:\n",
        "                    i, j = node_index[src], node_index[dst]\n",
        "                    self.adjacency_matrix[i, j] = 1\n",
        "                    self.adjacency_matrix[j, i] = 1  # Assume undirected graph\n",
        "\n",
        "    def get_data(self):\n",
        "        \"\"\"Returns the full dataset: features, labels, and adjacency matrix.\"\"\"\n",
        "        return self.X, self.y, self.adjacency_matrix\n",
        "\n",
        "    def get_label_mapping(self):\n",
        "        \"\"\"Returns the mapping from original labels to encoded integers.\"\"\"\n",
        "        return self.label_mapping\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"\n",
        "    A simple data loader for batching and shuffling CoraDataset data.\n",
        "\n",
        "    Args:\n",
        "        X (np.array): Feature matrix.\n",
        "        y (np.array): Labels.\n",
        "        adjacency_matrix (np.array): Dense adjacency matrix.\n",
        "        batch_size (int): Number of samples per batch.\n",
        "        shuffle (bool): Whether to shuffle the data at the beginning of each iteration.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, y, adjacency_matrix, batch_size=1, shuffle=False):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.num_samples = X.shape[0]\n",
        "        self.order = np.arange(self.num_samples)\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Initializes the iterator.\"\"\"\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.order)\n",
        "        self.index = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Fetches the next batch of data.\"\"\"\n",
        "        if self.index >= self.num_samples:\n",
        "            raise StopIteration\n",
        "\n",
        "        # Get indices for the current batch\n",
        "        start = self.index\n",
        "        end = min(self.index + self.batch_size, self.num_samples)\n",
        "        batch_indices = self.order[start:end]\n",
        "\n",
        "        # Fetch the batch\n",
        "        X_batch = self.X[batch_indices]\n",
        "        y_batch = self.y[batch_indices]\n",
        "        adjacency_batch = self.adjacency_matrix[batch_indices][:, batch_indices]\n",
        "\n",
        "        self.index += self.batch_size\n",
        "        return X_batch, y_batch, adjacency_batch\n",
        "\n",
        "import sys\n",
        "sys.path.append('./python')\n",
        "sys.path.append('./apps')\n",
        "import needle as ndl\n",
        "\n",
        "def softmax_loss(Z, y_one_hot):\n",
        "    \"\"\"Return softmax loss.  Note that for the purposes of this assignment,\n",
        "    you don't need to worry about \"nicely\" scaling the numerical properties\n",
        "    of the log-sum-exp computation, but can just compute this directly.\n",
        "\n",
        "    Args:\n",
        "        Z (ndl.Tensor[np.float32]): 2D Tensor of shape\n",
        "            (batch_size, num_classes), containing the logit predictions for\n",
        "            each class.\n",
        "        y (ndl.Tensor[np.int8]): 2D Tensor of shape (batch_size, num_classes)\n",
        "            containing a 1 at the index of the true label of each example and\n",
        "            zeros elsewhere.\n",
        "\n",
        "    Returns:\n",
        "        Average softmax loss over the sample. (ndl.Tensor[np.float32])\n",
        "    \"\"\"\n",
        "    ### BEGIN YOUR SOLUTION\n",
        "    m = Z.shape[0]\n",
        "    exps = ndl.ops.exp(Z)\n",
        "    log = ndl.ops.log(ndl.ops.summation(exps, axes=(1, )))\n",
        "    Z1 = ndl.ops.summation(log)\n",
        "    Z2 = ndl.ops.summation(Z * y_one_hot)\n",
        "    return (Z1 - Z2) / m\n",
        "    ### END YOUR SOLUTION\n",
        "\n",
        "def nn_epoch(X, y, W1, W2, lr=0.1, batch=100):\n",
        "    \"\"\"Run a single epoch of SGD for a two-layer neural network defined by the\n",
        "    weights W1 and W2 (with no bias terms):\n",
        "        logits = ReLU(X * W1) * W1\n",
        "    The function should use the step size lr, and the specified batch size (and\n",
        "    again, without randomizing the order of X).\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray[np.float32]): 2D input array of size\n",
        "            (num_examples x input_dim).\n",
        "        y (np.ndarray[np.uint8]): 1D class label array of size (num_examples,)\n",
        "        W1 (ndl.Tensor[np.float32]): 2D array of first layer weights, of shape\n",
        "            (input_dim, hidden_dim)\n",
        "        W2 (ndl.Tensor[np.float32]): 2D array of second layer weights, of shape\n",
        "            (hidden_dim, num_classes)\n",
        "        lr (float): step size (learning rate) for SGD\n",
        "        batch (int): size of SGD mini-batch\n",
        "\n",
        "    Returns:\n",
        "        Tuple: (W1, W2)\n",
        "            W1: ndl.Tensor[np.float32]\n",
        "            W2: ndl.Tensor[np.float32]\n",
        "    \"\"\"\n",
        "\n",
        "    ### BEGIN YOUR SOLUTION\n",
        "    m = X.shape[0]\n",
        "    for i in range(0, m, batch):\n",
        "        X_batch = X[i : i+batch]\n",
        "        y_batch = y[i : i+batch]\n",
        "        X_batch = ndl.Tensor(X_batch)\n",
        "        Z1 = ndl.ops.relu(X_batch @ W1)\n",
        "        Z = Z1 @ W2\n",
        "        y_one_hot = np.zeros(Z.shape, dtype=\"float32\")\n",
        "        y_one_hot[np.arange(Z.shape[0]),y_batch] = 1\n",
        "        loss = softmax_loss(Z, ndl.Tensor(y_one_hot))\n",
        "        loss.backward()\n",
        "        w1_grad = W1.grad\n",
        "        w2_grad = W2.grad\n",
        "        W1 = np.array(W1) - lr * w1_grad\n",
        "        W2 = np.array(W2) - lr * w2_grad\n",
        "        W1 = ndl.Tensor(W1)\n",
        "        W2 = ndl.Tensor(W2)\n",
        "    return W1, W2\n",
        "    ### END YOUR SOLUTION\n",
        "\n",
        "# Training function\n",
        "def train_gcn(model, dataset, num_epochs, learning_rate, batch_size):\n",
        "    \"\"\"\n",
        "    Train the GCN model on the Cora dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The GCN model instance.\n",
        "        dataset: CoraDataset instance providing data.\n",
        "        num_epochs: Number of training epochs.\n",
        "        learning_rate: Learning rate for gradient descent.\n",
        "        batch_size: Number of samples per batch.\n",
        "\n",
        "    Returns:\n",
        "        model: Trained GCN model.\n",
        "    \"\"\"\n",
        "    X, y, adjacency_matrix = dataset.get_data()\n",
        "    num_samples = X.shape[0]\n",
        "    num_classes = len(np.unique(y))\n",
        "\n",
        "    # Convert data to Needle Tensors\n",
        "    X_tensor = ndl.Tensor(X)\n",
        "    adjacency_tensor = ndl.Tensor(adjacency_matrix)\n",
        "    y_one_hot = np.eye(num_classes)[y]  # One-hot encode labels\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        num_batches = int(np.ceil(num_samples / batch_size))\n",
        "\n",
        "        for batch_idx in range(0, num_samples, batch_size):\n",
        "            # Fetch the batch\n",
        "            batch_end = min(batch_idx + batch_size, num_samples)\n",
        "            X_batch = X_tensor[batch_idx:batch_end]\n",
        "            y_batch = ndl.Tensor(y_one_hot[batch_idx:batch_end])\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(X_batch, adjacency_tensor)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = softmax_loss(logits, y_batch)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update weights\n",
        "            for param in model.parameters():\n",
        "                param.data -= learning_rate * param.grad.data\n",
        "                param.grad = None  # Reset gradients\n",
        "\n",
        "            epoch_loss += loss.data\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / num_batches}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_gcn(model, dataset):\n",
        "    \"\"\"\n",
        "    Evaluate the GCN model on the dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The trained GCN model.\n",
        "        dataset: CoraDataset instance providing data.\n",
        "\n",
        "    Returns:\n",
        "        accuracy: Accuracy of the model on the dataset.\n",
        "    \"\"\"\n",
        "    X, y, adjacency_matrix = dataset.get_data()\n",
        "    num_samples = X.shape[0]\n",
        "\n",
        "    # Convert data to Needle Tensors\n",
        "    X_tensor = ndl.Tensor(X)\n",
        "    adjacency_tensor = ndl.Tensor(adjacency_matrix)\n",
        "\n",
        "    # Forward pass\n",
        "    logits = model(X_tensor, adjacency_tensor)\n",
        "    predictions = np.argmax(logits.data, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(predictions == y)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "rHrs1z-pyL6h",
        "outputId": "e2d9adab-c31d-45e8-a082-7a58a4915189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using needle backend\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'needle.data.datasets.mnist_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-92286d3a2b3d>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./apps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneedle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mndl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/./python/needle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/./python/needle/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/./python/needle/data/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmnist_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mndarray_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcifar10_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mptb_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'needle.data.datasets.mnist_dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "qf5HguYi2UYA",
        "outputId": "269e4cb5-6855-4212-f66c-6ca8cc66c277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:57 (find_package):\n",
            "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
            "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
            "  set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- CUDA_FOUND: TRUE\n",
            "-- Found cuda, building cuda backend\n",
            "Wed Dec 11 17:51:56 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (0.3s)\n",
            "-- Generating done (0.3s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.modules.clear()"
      ],
      "metadata": {
        "id": "mwtDC6MJ24yk"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import needle.nn as nn\n",
        "# Example usage\n",
        "content_path = './data/cora/cora.content'\n",
        "cites_path = './data/cora/cora.cites'\n",
        "cora_dataset = CoraDataset(content_path, cites_path)\n",
        "\n",
        "# Initialize GCN model\n",
        "in_features = cora_dataset.X.shape[1]\n",
        "hidden_features = 16\n",
        "out_features = len(np.unique(cora_dataset.y))\n",
        "print(in_features)\n",
        "print(out_features)\n",
        "Conv = nn.Conv\n",
        "gcn_model = nn.GCN(in_features, hidden_features, out_features)\n",
        "# Train GCN model\n",
        "trained_gcn = train_gcn(gcn_model, cora_dataset, num_epochs=100, learning_rate=0.01, batch_size=64)\n",
        "# Evaluate GCN model\n",
        "accuracy = evaluate_gcn(trained_gcn, cora_dataset)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "PpT5bfroyQ0w",
        "outputId": "0c27ec6a-8d19-4f13-fe5d-6b0f18fa38b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1433\n",
            "7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'needle.nn' has no attribute 'GCN'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-c877b0241145>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mConv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgcn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train GCN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtrained_gcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcora_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'needle.nn' has no attribute 'GCN'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Sparse Matrix Definiation.\n",
        "In this project, we defined a new way to represent a sparse matrix(a type of matrix that contains a significant number of zero elements compared to the total number of elements in the matrix.) - **COO (Coordinate) format**. \\\n",
        "The COO (Coordinate) format is a representation of a sparse matrix that stores only the nonzero elements along with their row and column indices. It is efficient in terms of memory usage for sparse matrices because it avoids storing zero values.\\\n",
        "### Key Components:\n",
        "\n",
        "\n",
        "1.   Values (data): A list or array of the nonzero elements in the matrix.\n",
        "2.   Row indices (row): A list or array specifying the row index for each nonzero element.\n",
        "3. Column indices (col): A list or array specifying the column index for each nonzero element.\n",
        "\n",
        "###Properties:\n",
        "1. Flexible: Allows easy manipulation, such as matrix construction from nonzero entries.\n",
        "2. Duplicates: COO format allows duplicate entries. To obtain the actual matrix, these duplicates need to be summed.\n",
        "3. Conversion: Often converted to other formats like CSR (Compressed Sparse Row) or CSC (Compressed Sparse Column) for efficient matrix operations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NBwt22_ObUkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First, we are going to randomly generate a sparse matrix in normal NDArray format. It is a 10 * 10 matrix with 10 non-zero elements."
      ],
      "metadata": {
        "id": "NBbzz7ACi1sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle\n",
        "import numpy as np\n",
        "from backend_ndarray.ndarray import *\n",
        "\n",
        "np.random.seed(0)\n",
        "device = cuda()\n",
        "# Dimensions of the matrix\n",
        "rows, cols = 10, 10\n",
        "nonzero_elements = 10\n",
        "\n",
        "# Initialize a sparse matrix with all zeros\n",
        "matrix = np.zeros((rows, cols))\n",
        "\n",
        "# Randomly generate indices for nonzero elements\n",
        "row_indices = np.random.choice(rows, nonzero_elements, replace=True)\n",
        "col_indices = np.random.choice(cols, nonzero_elements, replace=True)\n",
        "\n",
        "# Generate random values for the nonzero elements\n",
        "values = np.random.random(nonzero_elements)\n",
        "\n",
        "# Populate the matrix\n",
        "for r, c, v in zip(row_indices, col_indices, values):\n",
        "    matrix[r, c] = v\n",
        "\n",
        "orig_matrix = NDArray(matrix, device=device)\n",
        "orig_matrix"
      ],
      "metadata": {
        "id": "N-Sr6XHhdH7t",
        "outputId": "eec30d0c-f5c5-49fa-d906-99460a22db3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0.         0.         0.         0.         0.         0.\n",
              "  0.07103606 0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.7991586  0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.87001216 0.0202184  0.        ]\n",
              " [0.         0.46147937 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.9786183  0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.83261985 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.77815676 0.         0.         0.        ]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Then, we are going to transform it to a sparse matrix."
      ],
      "metadata": {
        "id": "8pAHofaUjG1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix = orig_matrix.to_sparse()\n",
        "sparse_matrix"
      ],
      "metadata": {
        "id": "R3gQhP-3jGYZ",
        "outputId": "85fed6ec-17d8-472a-9b6c-95ef80a623db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseMatrix(nnz=8, shape=(10, 10),\n",
              "  data=[0.07103606 0.7991586  0.87001216 0.0202184  0.46147937 0.9786183\n",
              " 0.83261985 0.77815676],\n",
              "  row_indices=[0 2 3 3 4 5 7 9],\n",
              "  col_indices=[6 8 7 8 1 7 1 6])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the sparse matrix contains three length 10 array, `data`, `row_indices` and `col_indices`. The `data` represents the values of the all the non-zero elements inside the matrix, while `row_indices` and `col_indices` represents the row and column index of each non-zero element's index.\n",
        "\n",
        "We can also switch the sparse matrix back to dense matrix by calling `to_dense()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "CPaUh5xojQ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = sparse_matrix.to_dense()\n",
        "dense_matrix"
      ],
      "metadata": {
        "id": "aeLbPoXAkCyq",
        "outputId": "fa04e506-badd-4990-995f-a52aa69bbd73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0.         0.         0.         0.         0.         0.\n",
              "  0.07103606 0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.7991586  0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.87001216 0.0202184  0.        ]\n",
              " [0.         0.46147937 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.9786183  0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.83261985 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.77815676 0.         0.         0.        ]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Sparse Matrix Multiplication\n",
        "### COO Format Matrix Multiplication\n",
        "\n",
        "Matrix multiplication in the **COO (Coordinate)** format involves multiplying two sparse matrices that are represented in the COO format. Since the COO format only stores nonzero elements along with their row and column indices, performing multiplication requires processing each nonzero element and its corresponding coordinates.\n",
        "\n",
        "#### Step 1: Represent the Matrices in COO Format\n",
        "Assume two matrices A and B, both stored in COO format. They are represented by the following components:\n",
        "\n",
        "- **Matrix A**:\n",
        "  - `A_data`: Nonzero values in matrix A.\n",
        "  - `A_row`: Row indices of the nonzero values in A.\n",
        "  - `A_col`: Column indices of the nonzero values in A.\n",
        "\n",
        "- **Matrix B**:\n",
        "  - `B_data`: Nonzero values in matrix B.\n",
        "  - `B_row`: Row indices of the nonzero values in B.\n",
        "  - `B_col`: Column indices of the nonzero values in B.\n",
        "\n",
        "Let matrix A be of size m × n and matrix B be of size n × p. The resulting matrix C will be of size m × p.\n",
        "\n",
        "#### Step 2: Initialize the Resultant Matrix\n",
        "The resulting matrix C will also be sparse and initially contain only zeros. In COO format, the result will have:\n",
        "\n",
        "- `C_data`: Nonzero values of the resulting matrix.\n",
        "- `C_row`: Row indices of the nonzero values in C.\n",
        "- `C_col`: Column indices of the nonzero values in C.\n",
        "\n",
        "#### Step 3: Compute Nonzero Elements of the Result\n",
        "To calculate C = A × B, follow these steps for each nonzero element of A:\n",
        "\n",
        "1. **Find the corresponding element in matrix B**: For each nonzero element A_ij in A, find the corresponding column indices of B. The row index in B must match the column index in A to compute the dot product.\n",
        "\n",
        "2. **Perform the multiplication**: For each pair of nonzero elements A_ij and B_jk, multiply them together and add to the corresponding entry in C:\n",
        "   \n",
        "   ```\n",
        "   C_ik = C_ik + A_ij × B_jk\n",
        "   ```\n",
        "\n",
        "3. **Store the result**: If C_ik is nonzero after the above addition, store the result in the COO format:\n",
        "   - Add the value of C_ik to `C_data`.\n",
        "   - Add the row index i to `C_row`.\n",
        "   - Add the column index k to `C_col`.\n",
        "\n",
        "#### Step 4: Handle Sparse Properties\n",
        "Since the result matrix C is also sparse, ensure that only nonzero values are stored. If the sum of C_ik is zero, it should not be stored in the COO format.\n",
        "#### Define two sparse matrices.\n"
      ],
      "metadata": {
        "id": "V7knxQA5kTql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m, n, p = 500, 500, 500\n",
        "device = cuda()\n",
        "nnz = 100\n",
        "# Initialize a sparse matrix with all zeros\n",
        "matrix1 = np.zeros((m, n))\n",
        "matrix2 = np.zeros((n, p))\n",
        "\n",
        "# Randomly generate indices for nonzero elements\n",
        "row_indices_1 = np.random.choice(m, nnz, replace=True)\n",
        "col_indices_1 = np.random.choice(n, nnz, replace=True)\n",
        "row_indices_2 = np.random.choice(n, nnz, replace=True)\n",
        "col_indices_2 = np.random.choice(p, nnz, replace=True)\n",
        "\n",
        "# Generate random values for the nonzero elements\n",
        "values_1 = np.random.random(nnz)\n",
        "values_2 = np.random.random(nnz)\n",
        "\n",
        "# Populate the matrix\n",
        "for r, c, v in zip(row_indices_1, col_indices_2, values_1):\n",
        "    matrix1[r, c] = v\n",
        "for r, c, v in zip(row_indices_2, col_indices_2, values_2):\n",
        "    matrix2[r, c] = v\n",
        "\n",
        "dense_matrix1 = NDArray(matrix1, device=device)\n",
        "dense_matrix2 = NDArray(matrix2, device=device)\n",
        "dense_matrix1, dense_matrix2"
      ],
      "metadata": {
        "id": "SL-cMfnNkkQu",
        "outputId": "5c57ebdf-221b-47a0-e596-6a0b8fdd7da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  ...\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]], device=cuda()),\n",
              " NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  ...\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]], device=cuda()))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dense matrices to sparse matrices.\n",
        "sparse_matrix1 = dense_matrix1.to_sparse()\n",
        "sparse_matrix2 = dense_matrix2.to_sparse()\n",
        "sparse_matrix1, sparse_matrix2"
      ],
      "metadata": {
        "id": "NHE20CY8l80J",
        "outputId": "80f8b170-094c-4261-ecd6-b98f51ffb8ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(SparseMatrix(nnz=100, shape=(500, 500),\n",
              "   data=[0.10029394 0.46357542 0.05537432 0.76532525 0.37416998 0.35561273\n",
              "  0.6304479  0.29214752 0.4783703  0.40724117 0.3960597  0.58641016\n",
              "  0.13248764 0.96157014 0.6178767  0.23170163 0.79920256 0.07952208\n",
              "  0.96193635 0.77058077 0.1314828  0.29302028 0.14484777 0.49739137\n",
              "  0.97749513 0.18327984 0.42468548 0.9473706  0.63947254 0.21550767\n",
              "  0.09784448 0.22431703 0.8638556  0.72559434 0.11753186 0.05342718\n",
              "  0.20747007 0.24536721 0.7168597  0.82211775 0.14694664 0.01323686\n",
              "  0.27762872 0.9065555  0.8621915  0.58678436 0.9037197  0.9295293\n",
              "  0.08960304 0.14814086 0.02566272 0.87650526 0.08342244 0.9608347\n",
              "  0.21331197 0.5654213  0.42053947 0.06395527 0.8605512  0.23223414\n",
              "  0.66991657 0.3472335  0.511319   0.55219245 0.08110139 0.7270443\n",
              "  0.4856276  0.26211816 0.13690028 0.13206811 0.6720478  0.33314514\n",
              "  0.01642963 0.2703279  0.58447605 0.9493188  0.94043195 0.87428796\n",
              "  0.7308558  0.7740473  0.68328136 0.9413777  0.5573688  0.48805627\n",
              "  0.28173012 0.84894353 0.25394166 0.33815897 0.97291946 0.24082878\n",
              "  0.01142746 0.5182007  0.9818294  0.30159864 0.3685846  0.5173791\n",
              "  0.7486636  0.45614058 0.7851529  0.18984792],\n",
              "   row_indices=[ 31  31  42  38  32  53  53  42  47  48  28  57  69  82  84  91  99  94\n",
              "  105  95  98 121 128 127 119 128 127 147 131 147 148 143 151 163 163 169\n",
              "  185 178 183 180 197 203 202 207 227 244 244 257 256 262 265 267 273 279\n",
              "  288 290 292 291 304 305 321 324 334 335 341 349 358 368 356 370 369 373\n",
              "  376 387 388 384 389 396 398 397 405 398 418 420 425 426 423 430 442 442\n",
              "  448 449 452 461 460 459 488 487 487 488],\n",
              "   col_indices=[373 376 120 146 291 241  83 396 480 191 359 423 307 198 174 455  43 238\n",
              "  357  93  81 297 286 475 150 114 368 254 329 437 470 384 372 440 292 136\n",
              "  209 147 323 209 379 405 347 164  63 168 221 322  87 345 129 414 340 106\n",
              "  136 291  72  39  87 195 111 201 442   2 116  13 459 439 491  25 160  24\n",
              "  253 314  69 274 289 433  80  94 203 348 455  29 341  93 446 145  16  44\n",
              "  347 189 498 372  28 176 273 320  91 105]),\n",
              " SparseMatrix(nnz=100, shape=(500, 500),\n",
              "   data=[0.3708528  0.39902532 0.51001686 0.85772264 0.3267009  0.5361775\n",
              "  0.01203622 0.72416764 0.06271295 0.39843425 0.990345   0.251941\n",
              "  0.03330463 0.6969972  0.42403224 0.9040444  0.01560606 0.37381315\n",
              "  0.58759964 0.13105524 0.69002503 0.9591666  0.16053882 0.07695644\n",
              "  0.37992695 0.3068101  0.5757512  0.25942257 0.3277204  0.15941447\n",
              "  0.7963915  0.1154843  0.79979587 0.8155238  0.75677866 0.7774076\n",
              "  0.4569114  0.6144647  0.49030533 0.8820414  0.9564057  0.69962204\n",
              "  0.03536244 0.45985588 0.9518745  0.45860395 0.54380596 0.57754296\n",
              "  0.18523233 0.6956254  0.39267567 0.61848027 0.28351885 0.4090541\n",
              "  0.12886056 0.59098417 0.9742562  0.86948854 0.09961493 0.0446123\n",
              "  0.2728219  0.63876176 0.94530153 0.22116092 0.25868407 0.90398395\n",
              "  0.05684808 0.9589827  0.6455702  0.0163285  0.8207671  0.9088437\n",
              "  0.18115096 0.7786954  0.5188351  0.06807408 0.9292914  0.42879573\n",
              "  0.9594333  0.43040243 0.3567069  0.8490383  0.4541624  0.9894098\n",
              "  0.35536885 0.2531912  0.24002028 0.03307459 0.23274413 0.4012595\n",
              "  0.19705428 0.62889844 0.16295442 0.6813925  0.45722345 0.7885455\n",
              "  0.1871309  0.45813882 0.6360611  0.2775961 ],\n",
              "   row_indices=[ 40  32  24  27  27  67  33  43  67  29  36  44  73  13  35  11  61  79\n",
              "   41  88 104 111 125 111 121 129 151 152 138 148 156 133 166 174 182 184\n",
              "  189 199 197 197 204 212 216 207 217 215 214 223 218 228 234 232 251 256\n",
              "  259 258 255 265 259 267 274 290 287 290 295 291 287 297 300 302 309 307\n",
              "  326 327 349 353 364 341 374 381 387 393 394 382 407 418 421 423 429 434\n",
              "  438 437 459 466 467 469 486 488 491 495],\n",
              "   col_indices=[372 423 273 297 307 221 455 341  28 329  81  87 442 129 491  39  93 376\n",
              "  347  72 459  43 274 359  80 114 405 291 414 480 348  87 323 498 145 368\n",
              "  322 440 320 111 396 150 289 176 174  91 253 286 106 437 357  13 254 120\n",
              "   69 433 314 191  24  25 168 439 116 160 209 373 189 384 241  16 201 345\n",
              "  446 209 291 238  94 379  29 146  63 105 195 203 470 147 455 347 136 164\n",
              "  292 475 372 340  93 136  44  83 198   2]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication between dense matrices."
      ],
      "metadata": {
        "id": "vwtVy7Xilioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "correct_result = dense_matrix1 @ dense_matrix2\n",
        "end = time.time()\n",
        "print(f\"Time taken for dense-dense matrix multipliction: {(end - start)*1000} ms\")\n",
        "correct_result"
      ],
      "metadata": {
        "id": "PcR5JUpvlaUV",
        "outputId": "a4a5f12b-4795-4efe-9d8b-39a45248a269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for dense-dense matrix multipliction: 0.3287792205810547 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " ...\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication between sparse matrices."
      ],
      "metadata": {
        "id": "mtJqrryEmNso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = sparse_matrix1 @ sparse_matrix2\n",
        "print(result)\n",
        "# result = result.to_dense() # when flag = True return dense\n",
        "end = time.time()\n",
        "print(f\"Time taken for sparse-sparse matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "rQdvy4RJmXcv",
        "outputId": "85cda6a2-b393-4b0d-f13a-363c4166baf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Time taken for sparse-sparse matrix multipliction: 3.0074119567871094 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = sparse_matrix1 @ dense_matrix2\n",
        "result = result\n",
        "end = time.time()\n",
        "print(f\"Time taken for sparse-dense matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "a-9KWLwRnuyt",
        "outputId": "722314cd-1b50-4c4f-f731-aed4e7ff55be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for sparse-dense matrix multipliction: 0.49948692321777344 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = dense_matrix1 @ sparse_matrix2\n",
        "result = result\n",
        "end = time.time()\n",
        "print(f\"Time taken for dense-sparse matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "1ukY2wXRn4dk",
        "outputId": "d2eb5a5a-310f-4c38-e1c5-76aa201fab4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for dense-sparse matrix multipliction: 0.3407001495361328 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m backend_ndarray.ndarray"
      ],
      "metadata": {
        "id": "i7I2JjuJkVLf",
        "outputId": "70ec8b47-02ef-4385-d21c-6b7f753d3c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'backend_ndarray.ndarray' found in sys.modules after import of package 'backend_ndarray', but prior to execution of 'backend_ndarray.ndarray'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Time for dense @ dense: 0.225067138671875 ms\n",
            "Time for dense @ sparse: 0.9086132049560547 ms\n",
            "Time for sparse @ dense: 0.2598762512207031 ms\n",
            "Time for sparse @ sparse: 0.09012222290039062 ms\n",
            "Total time: 1.2586116790771484 ms\n",
            "dense @ sparse: True\n",
            "sparse @ dense: True\n",
            "sparse @ sparse: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network(GNN)\n",
        "A Graph Neural Network (GNN) is a type of neural network specifically designed to process and analyze data structured as graphs. In a graph, data is represented as nodes (vertices) connected by edges (links), which may have associated features or attributes.\n",
        "### Common GNN Architectures:\n",
        "1. Graph Convolutional Networks (GCN): Generalizes the concept of convolution to graphs.\n",
        "2. Graph Attention Networks (GAT): Uses attention mechanisms to weigh neighbor contributions.\n",
        "3. GraphSAGE: Focuses on efficient sampling and aggregating information from neighbors.\n",
        "\n",
        "In this project, we are going to implement Graph Convolutional Network(GCN) and use sparse matrix multiplication mechnisms we implemented to accelerate its forward and backward passes."
      ],
      "metadata": {
        "id": "6H_e4ZpKN7G2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrW9hda8kofS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}