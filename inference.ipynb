{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meii0606/Breaking-reCAPTCHAv2/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10-414/714: Deep Learning Systems - Final Project\n",
        "\n",
        "\n",
        "## **Sparse Matrix Multiplication on Graph Neural Network**\n",
        "\n",
        "**By Andrew Zhang, Jinkai Qiu & Yimei Wu**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In this project, we are going to implement **sparse matrix** class supported in Needle, **forward and backward pass of sparse matrix multiplication**, and its **application on Graph Neural Network(GNN)**.\n",
        "\n",
        "In this notebook, we are going to show how to **define sparse matrix**, perform **sparse matrix multiplication** and compare it with normal dense matrix multiplication. In addition, we will also show how it can be used in **GNN training.**\n",
        "\n"
      ],
      "metadata": {
        "id": "87NGEASXY4Ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone Required Repo and Install Required Packages"
      ],
      "metadata": {
        "id": "vtBJoltybBDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW1iuoBMCYyp",
        "outputId": "bf097a03-a6a0-4921-a6b2-035afab725ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/10714\n",
            "/content/drive/MyDrive/10714/final_proj\n",
            "fatal: destination path 'gnn_with_spmm' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 22 (delta 16), reused 11 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (22/22), 10.70 KiB | 17.00 KiB/s, done.\n",
            "From https://github.com/AndrewZhang76/gnn_with_spmm\n",
            "   aba4991..fe0cf9f  main       -> origin/main\n",
            "Updating aba4991..fe0cf9f\n",
            "Fast-forward\n",
            " inference.ipynb                          | 363 \u001b[32m++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-----------------\u001b[m\n",
            " python/needle/backend_ndarray/ndarray.py |  39 \u001b[32m++++\u001b[m\u001b[31m--\u001b[m\n",
            " src/ndarray_backend_cuda.cu              | 160 \u001b[32m++++++++++++++++\u001b[m\u001b[31m-------\u001b[m\n",
            " 3 files changed, 379 insertions(+), 183 deletions(-)\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.13.6\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/10714\n",
        "!mkdir -p final_proj\n",
        "%cd /content/drive/MyDrive/10714/final_proj\n",
        "!git clone https://github.com/AndrewZhang76/gnn_with_spmm.git\n",
        "%cd gnn_with_spmm/\n",
        "!git pull\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build"
      ],
      "metadata": {
        "id": "PidjQAHYbNf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/\n",
        "!make"
      ],
      "metadata": {
        "id": "-U1A2kF6CpzT",
        "outputId": "0b02d618-3c8c-42a4-dd65-db4099ee436d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Python: /usr/local/bin/python (found version \"3.10.12\") found components: Development Interpreter Development.Module Development.Embed\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/lib/python3.10/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:57 (find_package):\n",
            "  Policy CMP0146 is not set: The FindCUDA module is removed.  Run \"cmake\n",
            "  --help-policy CMP0146\" for policy details.  Use the cmake_policy command to\n",
            "  set the policy and suppress this warning.\n",
            "\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Found CUDA: /usr/local/cuda (found version \"12.2\")\n",
            "-- CUDA_FOUND: TRUE\n",
            "-- Found cuda, building cuda backend\n",
            "Tue Dec 10 05:27:35 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (6.0s)\n",
            "-- Generating done (0.3s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[-25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "In file included from /usr/local/cuda/include/thrust/detail/config/config.h:27,\n",
            "                 from /usr/local/cuda/include/thrust/detail/config.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:24,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13: warning: Thrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                           \n",
            "In file included from /usr/local/cuda/include/cub/util_arch.cuh:36,\n",
            "                 from /usr/local/cuda/include/cub/util_debug.cuh:40,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/config.h:43,\n",
            "                 from /usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23,\n",
            "                 from /usr/local/cuda/include/thrust/iterator/iterator_traits.h:62,\n",
            "                 from /usr/local/cuda/include/thrust/detail/sort.inl:21,\n",
            "                 from /usr/local/cuda/include/thrust/sort.h:1358,\n",
            "                 from /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/src/ndarray_backend_cuda.cu:8:\n",
            "/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13: warning: CUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COMPILER_DEPRECATION_SOFT(C++14, C++11);\n",
            "      |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                        \n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ],
      "metadata": {
        "id": "i4J1P8RQi38J",
        "outputId": "abcb6227-ef92-4df5-ac94-643c12d20e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Sparse Matrix Definiation.\n",
        "In this project, we defined a new way to represent a sparse matrix(a type of matrix that contains a significant number of zero elements compared to the total number of elements in the matrix.) - **COO (Coordinate) format**. \\\n",
        "The COO (Coordinate) format is a representation of a sparse matrix that stores only the nonzero elements along with their row and column indices. It is efficient in terms of memory usage for sparse matrices because it avoids storing zero values.\\\n",
        "### Key Components:\n",
        "\n",
        "\n",
        "1.   Values (data): A list or array of the nonzero elements in the matrix.\n",
        "2.   Row indices (row): A list or array specifying the row index for each nonzero element.\n",
        "3. Column indices (col): A list or array specifying the column index for each nonzero element.\n",
        "\n",
        "###Properties:\n",
        "1. Flexible: Allows easy manipulation, such as matrix construction from nonzero entries.\n",
        "2. Duplicates: COO format allows duplicate entries. To obtain the actual matrix, these duplicates need to be summed.\n",
        "3. Conversion: Often converted to other formats like CSR (Compressed Sparse Row) or CSC (Compressed Sparse Column) for efficient matrix operations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NBwt22_ObUkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First, we are going to randomly generate a sparse matrix in normal NDArray format. It is a 10 * 10 matrix with 10 non-zero elements."
      ],
      "metadata": {
        "id": "NBbzz7ACi1sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle\n",
        "import numpy as np\n",
        "from backend_ndarray.ndarray import *\n",
        "\n",
        "np.random.seed(0)\n",
        "device = cuda()\n",
        "# Dimensions of the matrix\n",
        "rows, cols = 10, 10\n",
        "nonzero_elements = 10\n",
        "\n",
        "# Initialize a sparse matrix with all zeros\n",
        "matrix = np.zeros((rows, cols))\n",
        "\n",
        "# Randomly generate indices for nonzero elements\n",
        "row_indices = np.random.choice(rows, nonzero_elements, replace=True)\n",
        "col_indices = np.random.choice(cols, nonzero_elements, replace=True)\n",
        "\n",
        "# Generate random values for the nonzero elements\n",
        "values = np.random.random(nonzero_elements)\n",
        "\n",
        "# Populate the matrix\n",
        "for r, c, v in zip(row_indices, col_indices, values):\n",
        "    matrix[r, c] = v\n",
        "\n",
        "orig_matrix = NDArray(matrix, device=device)\n",
        "orig_matrix"
      ],
      "metadata": {
        "id": "N-Sr6XHhdH7t",
        "outputId": "eec30d0c-f5c5-49fa-d906-99460a22db3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/final_proj/gnn_with_spmm/python/needle\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0.         0.         0.         0.         0.         0.\n",
              "  0.07103606 0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.7991586  0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.87001216 0.0202184  0.        ]\n",
              " [0.         0.46147937 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.9786183  0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.83261985 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.77815676 0.         0.         0.        ]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Then, we are going to transform it to a sparse matrix."
      ],
      "metadata": {
        "id": "8pAHofaUjG1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix = orig_matrix.to_sparse()\n",
        "sparse_matrix"
      ],
      "metadata": {
        "id": "R3gQhP-3jGYZ",
        "outputId": "85fed6ec-17d8-472a-9b6c-95ef80a623db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseMatrix(nnz=8, shape=(10, 10),\n",
              "  data=[0.07103606 0.7991586  0.87001216 0.0202184  0.46147937 0.9786183\n",
              " 0.83261985 0.77815676],\n",
              "  row_indices=[0 2 3 3 4 5 7 9],\n",
              "  col_indices=[6 8 7 8 1 7 1 6])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the sparse matrix contains three length 10 array, `data`, `row_indices` and `col_indices`. The `data` represents the values of the all the non-zero elements inside the matrix, while `row_indices` and `col_indices` represents the row and column index of each non-zero element's index.\n",
        "\n",
        "We can also switch the sparse matrix back to dense matrix by calling `to_dense()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "CPaUh5xojQ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = sparse_matrix.to_dense()\n",
        "dense_matrix"
      ],
      "metadata": {
        "id": "aeLbPoXAkCyq",
        "outputId": "fa04e506-badd-4990-995f-a52aa69bbd73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0.         0.         0.         0.         0.         0.\n",
              "  0.07103606 0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.7991586  0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.87001216 0.0202184  0.        ]\n",
              " [0.         0.46147937 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.9786183  0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.83261985 0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.         0.         0.         0.        ]\n",
              " [0.         0.         0.         0.         0.         0.\n",
              "  0.77815676 0.         0.         0.        ]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Sparse Matrix Multiplication\n",
        "### COO Format Matrix Multiplication\n",
        "\n",
        "Matrix multiplication in the **COO (Coordinate)** format involves multiplying two sparse matrices that are represented in the COO format. Since the COO format only stores nonzero elements along with their row and column indices, performing multiplication requires processing each nonzero element and its corresponding coordinates.\n",
        "\n",
        "#### Step 1: Represent the Matrices in COO Format\n",
        "Assume two matrices A and B, both stored in COO format. They are represented by the following components:\n",
        "\n",
        "- **Matrix A**:\n",
        "  - `A_data`: Nonzero values in matrix A.\n",
        "  - `A_row`: Row indices of the nonzero values in A.\n",
        "  - `A_col`: Column indices of the nonzero values in A.\n",
        "\n",
        "- **Matrix B**:\n",
        "  - `B_data`: Nonzero values in matrix B.\n",
        "  - `B_row`: Row indices of the nonzero values in B.\n",
        "  - `B_col`: Column indices of the nonzero values in B.\n",
        "\n",
        "Let matrix A be of size m × n and matrix B be of size n × p. The resulting matrix C will be of size m × p.\n",
        "\n",
        "#### Step 2: Initialize the Resultant Matrix\n",
        "The resulting matrix C will also be sparse and initially contain only zeros. In COO format, the result will have:\n",
        "\n",
        "- `C_data`: Nonzero values of the resulting matrix.\n",
        "- `C_row`: Row indices of the nonzero values in C.\n",
        "- `C_col`: Column indices of the nonzero values in C.\n",
        "\n",
        "#### Step 3: Compute Nonzero Elements of the Result\n",
        "To calculate C = A × B, follow these steps for each nonzero element of A:\n",
        "\n",
        "1. **Find the corresponding element in matrix B**: For each nonzero element A_ij in A, find the corresponding column indices of B. The row index in B must match the column index in A to compute the dot product.\n",
        "\n",
        "2. **Perform the multiplication**: For each pair of nonzero elements A_ij and B_jk, multiply them together and add to the corresponding entry in C:\n",
        "   \n",
        "   ```\n",
        "   C_ik = C_ik + A_ij × B_jk\n",
        "   ```\n",
        "\n",
        "3. **Store the result**: If C_ik is nonzero after the above addition, store the result in the COO format:\n",
        "   - Add the value of C_ik to `C_data`.\n",
        "   - Add the row index i to `C_row`.\n",
        "   - Add the column index k to `C_col`.\n",
        "\n",
        "#### Step 4: Handle Sparse Properties\n",
        "Since the result matrix C is also sparse, ensure that only nonzero values are stored. If the sum of C_ik is zero, it should not be stored in the COO format.\n",
        "#### Define two sparse matrices.\n"
      ],
      "metadata": {
        "id": "V7knxQA5kTql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m, n, p = 500, 500, 500\n",
        "device = cuda()\n",
        "nnz = 100\n",
        "# Initialize a sparse matrix with all zeros\n",
        "matrix1 = np.zeros((m, n))\n",
        "matrix2 = np.zeros((n, p))\n",
        "\n",
        "# Randomly generate indices for nonzero elements\n",
        "row_indices_1 = np.random.choice(m, nnz, replace=True)\n",
        "col_indices_1 = np.random.choice(n, nnz, replace=True)\n",
        "row_indices_2 = np.random.choice(n, nnz, replace=True)\n",
        "col_indices_2 = np.random.choice(p, nnz, replace=True)\n",
        "\n",
        "# Generate random values for the nonzero elements\n",
        "values_1 = np.random.random(nnz)\n",
        "values_2 = np.random.random(nnz)\n",
        "\n",
        "# Populate the matrix\n",
        "for r, c, v in zip(row_indices_1, col_indices_2, values_1):\n",
        "    matrix1[r, c] = v\n",
        "for r, c, v in zip(row_indices_2, col_indices_2, values_2):\n",
        "    matrix2[r, c] = v\n",
        "\n",
        "dense_matrix1 = NDArray(matrix1, device=device)\n",
        "dense_matrix2 = NDArray(matrix2, device=device)\n",
        "dense_matrix1, dense_matrix2"
      ],
      "metadata": {
        "id": "SL-cMfnNkkQu",
        "outputId": "5c57ebdf-221b-47a0-e596-6a0b8fdd7da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  ...\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]], device=cuda()),\n",
              " NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  ...\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]\n",
              "  [0. 0. 0. ... 0. 0. 0.]], device=cuda()))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dense matrices to sparse matrices.\n",
        "sparse_matrix1 = dense_matrix1.to_sparse()\n",
        "sparse_matrix2 = dense_matrix2.to_sparse()\n",
        "sparse_matrix1, sparse_matrix2"
      ],
      "metadata": {
        "id": "NHE20CY8l80J",
        "outputId": "80f8b170-094c-4261-ecd6-b98f51ffb8ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(SparseMatrix(nnz=100, shape=(500, 500),\n",
              "   data=[0.10029394 0.46357542 0.05537432 0.76532525 0.37416998 0.35561273\n",
              "  0.6304479  0.29214752 0.4783703  0.40724117 0.3960597  0.58641016\n",
              "  0.13248764 0.96157014 0.6178767  0.23170163 0.79920256 0.07952208\n",
              "  0.96193635 0.77058077 0.1314828  0.29302028 0.14484777 0.49739137\n",
              "  0.97749513 0.18327984 0.42468548 0.9473706  0.63947254 0.21550767\n",
              "  0.09784448 0.22431703 0.8638556  0.72559434 0.11753186 0.05342718\n",
              "  0.20747007 0.24536721 0.7168597  0.82211775 0.14694664 0.01323686\n",
              "  0.27762872 0.9065555  0.8621915  0.58678436 0.9037197  0.9295293\n",
              "  0.08960304 0.14814086 0.02566272 0.87650526 0.08342244 0.9608347\n",
              "  0.21331197 0.5654213  0.42053947 0.06395527 0.8605512  0.23223414\n",
              "  0.66991657 0.3472335  0.511319   0.55219245 0.08110139 0.7270443\n",
              "  0.4856276  0.26211816 0.13690028 0.13206811 0.6720478  0.33314514\n",
              "  0.01642963 0.2703279  0.58447605 0.9493188  0.94043195 0.87428796\n",
              "  0.7308558  0.7740473  0.68328136 0.9413777  0.5573688  0.48805627\n",
              "  0.28173012 0.84894353 0.25394166 0.33815897 0.97291946 0.24082878\n",
              "  0.01142746 0.5182007  0.9818294  0.30159864 0.3685846  0.5173791\n",
              "  0.7486636  0.45614058 0.7851529  0.18984792],\n",
              "   row_indices=[ 31  31  42  38  32  53  53  42  47  48  28  57  69  82  84  91  99  94\n",
              "  105  95  98 121 128 127 119 128 127 147 131 147 148 143 151 163 163 169\n",
              "  185 178 183 180 197 203 202 207 227 244 244 257 256 262 265 267 273 279\n",
              "  288 290 292 291 304 305 321 324 334 335 341 349 358 368 356 370 369 373\n",
              "  376 387 388 384 389 396 398 397 405 398 418 420 425 426 423 430 442 442\n",
              "  448 449 452 461 460 459 488 487 487 488],\n",
              "   col_indices=[373 376 120 146 291 241  83 396 480 191 359 423 307 198 174 455  43 238\n",
              "  357  93  81 297 286 475 150 114 368 254 329 437 470 384 372 440 292 136\n",
              "  209 147 323 209 379 405 347 164  63 168 221 322  87 345 129 414 340 106\n",
              "  136 291  72  39  87 195 111 201 442   2 116  13 459 439 491  25 160  24\n",
              "  253 314  69 274 289 433  80  94 203 348 455  29 341  93 446 145  16  44\n",
              "  347 189 498 372  28 176 273 320  91 105]),\n",
              " SparseMatrix(nnz=100, shape=(500, 500),\n",
              "   data=[0.3708528  0.39902532 0.51001686 0.85772264 0.3267009  0.5361775\n",
              "  0.01203622 0.72416764 0.06271295 0.39843425 0.990345   0.251941\n",
              "  0.03330463 0.6969972  0.42403224 0.9040444  0.01560606 0.37381315\n",
              "  0.58759964 0.13105524 0.69002503 0.9591666  0.16053882 0.07695644\n",
              "  0.37992695 0.3068101  0.5757512  0.25942257 0.3277204  0.15941447\n",
              "  0.7963915  0.1154843  0.79979587 0.8155238  0.75677866 0.7774076\n",
              "  0.4569114  0.6144647  0.49030533 0.8820414  0.9564057  0.69962204\n",
              "  0.03536244 0.45985588 0.9518745  0.45860395 0.54380596 0.57754296\n",
              "  0.18523233 0.6956254  0.39267567 0.61848027 0.28351885 0.4090541\n",
              "  0.12886056 0.59098417 0.9742562  0.86948854 0.09961493 0.0446123\n",
              "  0.2728219  0.63876176 0.94530153 0.22116092 0.25868407 0.90398395\n",
              "  0.05684808 0.9589827  0.6455702  0.0163285  0.8207671  0.9088437\n",
              "  0.18115096 0.7786954  0.5188351  0.06807408 0.9292914  0.42879573\n",
              "  0.9594333  0.43040243 0.3567069  0.8490383  0.4541624  0.9894098\n",
              "  0.35536885 0.2531912  0.24002028 0.03307459 0.23274413 0.4012595\n",
              "  0.19705428 0.62889844 0.16295442 0.6813925  0.45722345 0.7885455\n",
              "  0.1871309  0.45813882 0.6360611  0.2775961 ],\n",
              "   row_indices=[ 40  32  24  27  27  67  33  43  67  29  36  44  73  13  35  11  61  79\n",
              "   41  88 104 111 125 111 121 129 151 152 138 148 156 133 166 174 182 184\n",
              "  189 199 197 197 204 212 216 207 217 215 214 223 218 228 234 232 251 256\n",
              "  259 258 255 265 259 267 274 290 287 290 295 291 287 297 300 302 309 307\n",
              "  326 327 349 353 364 341 374 381 387 393 394 382 407 418 421 423 429 434\n",
              "  438 437 459 466 467 469 486 488 491 495],\n",
              "   col_indices=[372 423 273 297 307 221 455 341  28 329  81  87 442 129 491  39  93 376\n",
              "  347  72 459  43 274 359  80 114 405 291 414 480 348  87 323 498 145 368\n",
              "  322 440 320 111 396 150 289 176 174  91 253 286 106 437 357  13 254 120\n",
              "   69 433 314 191  24  25 168 439 116 160 209 373 189 384 241  16 201 345\n",
              "  446 209 291 238  94 379  29 146  63 105 195 203 470 147 455 347 136 164\n",
              "  292 475 372 340  93 136  44  83 198   2]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication between dense matrices."
      ],
      "metadata": {
        "id": "vwtVy7Xilioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "correct_result = dense_matrix1 @ dense_matrix2\n",
        "end = time.time()\n",
        "print(f\"Time taken for dense-dense matrix multipliction: {(end - start)*1000} ms\")\n",
        "correct_result"
      ],
      "metadata": {
        "id": "PcR5JUpvlaUV",
        "outputId": "a4a5f12b-4795-4efe-9d8b-39a45248a269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for dense-dense matrix multipliction: 0.3287792205810547 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([[0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " ...\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]\n",
              " [0. 0. 0. ... 0. 0. 0.]], device=cuda())"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication between sparse matrices."
      ],
      "metadata": {
        "id": "mtJqrryEmNso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = sparse_matrix1 @ sparse_matrix2\n",
        "print(result)\n",
        "# result = result.to_dense() # when flag = True return dense\n",
        "end = time.time()\n",
        "print(f\"Time taken for sparse-sparse matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "rQdvy4RJmXcv",
        "outputId": "85cda6a2-b393-4b0d-f13a-363c4166baf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Time taken for sparse-sparse matrix multipliction: 3.0074119567871094 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = sparse_matrix1 @ dense_matrix2\n",
        "result = result\n",
        "end = time.time()\n",
        "print(f\"Time taken for sparse-dense matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "a-9KWLwRnuyt",
        "outputId": "722314cd-1b50-4c4f-f731-aed4e7ff55be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for sparse-dense matrix multipliction: 0.49948692321777344 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "result = dense_matrix1 @ sparse_matrix2\n",
        "result = result\n",
        "end = time.time()\n",
        "print(f\"Time taken for dense-sparse matrix multipliction: {(end - start)*1000} ms\")\n",
        "print(f\"Result Correction: \\n{np.allclose(correct_result.numpy(), result.numpy())}\")"
      ],
      "metadata": {
        "id": "1ukY2wXRn4dk",
        "outputId": "d2eb5a5a-310f-4c38-e1c5-76aa201fab4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for dense-sparse matrix multipliction: 0.3407001495361328 ms\n",
            "Result Correction: \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m backend_ndarray.ndarray"
      ],
      "metadata": {
        "id": "i7I2JjuJkVLf",
        "outputId": "70ec8b47-02ef-4385-d21c-6b7f753d3c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'backend_ndarray.ndarray' found in sys.modules after import of package 'backend_ndarray', but prior to execution of 'backend_ndarray.ndarray'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Time for dense @ dense: 0.225067138671875 ms\n",
            "Time for dense @ sparse: 0.9086132049560547 ms\n",
            "Time for sparse @ dense: 0.2598762512207031 ms\n",
            "Time for sparse @ sparse: 0.09012222290039062 ms\n",
            "Total time: 1.2586116790771484 ms\n",
            "dense @ sparse: True\n",
            "sparse @ dense: True\n",
            "sparse @ sparse: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network(GNN)\n",
        "A Graph Neural Network (GNN) is a type of neural network specifically designed to process and analyze data structured as graphs. In a graph, data is represented as nodes (vertices) connected by edges (links), which may have associated features or attributes.\n",
        "### Common GNN Architectures:\n",
        "1. Graph Convolutional Networks (GCN): Generalizes the concept of convolution to graphs.\n",
        "2. Graph Attention Networks (GAT): Uses attention mechanisms to weigh neighbor contributions.\n",
        "3. GraphSAGE: Focuses on efficient sampling and aggregating information from neighbors.\n",
        "\n",
        "In this project, we are going to implement Graph Convolutional Network(GCN) and use sparse matrix multiplication mechnisms we implemented to accelerate its forward and backward passes."
      ],
      "metadata": {
        "id": "6H_e4ZpKN7G2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrW9hda8kofS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}